from langgraph.graph import StateGraph, END
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain_community.tools.wikipedia.tool import WikipediaQueryRun
from langchain_community.utilities.wikipedia import WikipediaAPIWrapper
from langchain_chroma import Chroma
from langchain.agents import create_openai_functions_agent, Tool, AgentExecutor
from langchain.prompts import ChatPromptTemplate as LCChatPromptTemplate
from textwrap import dedent
from typing import TypedDict
from IPython.display import Image
from dotenv import load_dotenv
import os

# í™˜ê²½ ì„¤ì •
load_dotenv()

COSINE_SIMILARITY_THRESHOLD = 0.1


root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "."))  # ë£¨íŠ¸ ê²½ë¡œ
CHROMA_DBS_CONFIG = [
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/chroma"),
        "collection_name": "antibiotic_overuse"
    },
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/chroma"),
        "collection_name": "vitamin"
    },
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/others"),
        "collection_name": "others"
    },
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/vitamin_chroma"),
        "collection_name": "vitamin"
    },
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/soomin"),
        "collection_name": "soomin"
    },
    {
        "persist_directory": os.path.join(root_dir, "crawling/vector_store/chroma_pubmed_v3_large"),
        "collection_name": "langchain"
    }
]



# âœ… ìƒíƒœ ì •ì˜
class CompareState(TypedDict):
    """
    ë¹„êµ ë° ìš”ì•½ ì‘ì—…ì„ ìœ„í•œ ìƒíƒœë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """
    question: str
    translated_question: str
    social_knowledge: str
    latest_docs: list
    k_value: int
    final_answer: str
    db_has_data: bool 

# âœ… ëª¨ë¸ ì •ì˜
model = ChatOpenAI(model="gpt-4.1", temperature=0)
embedding_model = OpenAIEmbeddings(model="text-embedding-3-large")

# âœ… í”„ë¡¬í”„íŠ¸ ì •ì˜
COMPARE_PROMPT = LCChatPromptTemplate.from_messages([
    ("system", dedent("""
    ë‹¹ì‹ ì€ ì „ë¬¸ ì˜ë£Œ ì •ë³´ ìš”ì•½ê°€ì…ë‹ˆë‹¤.
    ì•„ë˜ ì‚¬ìš©ì ì§ˆë¬¸, ì‚¬íšŒí†µë… ì •ë³´, ìµœì‹  ì˜í•™ ë…¼ë¬¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í•µì‹¬ ë‹µë³€ë§Œ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    - ìµœì‹  ì—°êµ¬ ê²°ê³¼ê°€ ê¸°ì¡´ ì‚¬íšŒí†µë…ê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ë¹„êµí•˜ê³  ì¢…í•©ì ì¸ í•œê¸€ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.
    - ì‚¬íšŒí†µë…ì´ë‚˜ ìµœì‹  ë…¼ë¬¸ ì •ë³´ê°€ ì—†ë‹¤ë©´ í•´ë‹¹ ë¶€ë¶„ì€ 'ì •ë³´ ì—†ìŒ'ì´ë¼ê³  ì‘ì„±í•˜ì„¸ìš”.
    - ìµœì‹  ì˜í•™ ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ê·¸ ì‚¬ì‹¤ì„ ëª…í™•íˆ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.

    
    ë‹µë³€ì€ ì•„ë˜ì™€ ê°™ì´ 3ë¬¸ë‹¨ìœ¼ë¡œ êµ¬ì„±í•´ì„œ í•œê¸€ë¡œ ìµœì¢… ë‹µë³€í•´ì£¼ì„¸ìš”.

    1. ì‚¬íšŒí†µë… ì†Œê°œ
    2. ìµœì‹  ë…¼ë¬¸ ì†Œê°œ
    3. ê°„ë‹¨í•œ ë¹„êµê¸€
    """)),
    ("human", dedent("""
    ì‚¬ìš©ì ì§ˆë¬¸: {question}

    [ì‚¬íšŒí†µë… ì •ë³´]
    {social_knowledge}

    [ìµœì‹  ë…¼ë¬¸ ì •ë³´]
    {latest_docs}

    {db_status_message} 
    
    ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•˜ê³  ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í•œê¸€ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.
    """
    ))
])

# âœ… ë…¸ë“œ ì •ì˜

def translate_question(state: CompareState) -> CompareState:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” ë…¸ë“œ.
    """
    print(f"\n--- translate_question ---")
    translate_prompt = f"Translate the following Korean medical question into English: {state['question']}"
    translated = model.invoke(translate_prompt).content
    state["translated_question"] = translated
    print(f"ì›ë³¸ ì§ˆë¬¸: {state['question']}")
    print(f"ë²ˆì—­ëœ ì§ˆë¬¸: {state['translated_question']}")
    return state

def agent_search(state: CompareState) -> CompareState:
    """
    Wikipediaë¥¼ í†µí•´ ì‚¬íšŒ í†µë… ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” Agent ë…¸ë“œ.
    """
    print(f"\n--- agent_search ---")
    wiki_wrapper = WikipediaAPIWrapper(top_k_results=3) # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ëŠ˜ë ¤ë³¼ ìˆ˜ ìˆìŒ
    wiki_tool = WikipediaQueryRun(api_wrapper=wiki_wrapper)

    tools = [Tool(name="Wikipedia", func=wiki_tool.run, description="ì‚¬íšŒí†µë… ê²€ìƒ‰")]

    # ì—ì´ì „íŠ¸ í”„ë¡¬í”„íŠ¸ ê°œì„ : ë” ëª…í™•í•˜ê²Œ ê²€ìƒ‰ í›„ ìš”ì•½í•˜ë„ë¡ ì§€ì‹œ
    AGENT_PROMPT = LCChatPromptTemplate.from_messages([
        ("system", dedent("""
        ë„ˆëŠ” ë˜‘ë˜‘í•œ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì‚¬íšŒí†µë… ì •ë³´ë¥¼ Wikipediaì—ì„œ ê²€ìƒ‰í•´ì•¼ í•´.
        ê²€ìƒ‰ëœ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ì‚¬ìš©ì ì§ˆë¬¸ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í•µì‹¬ ì‚¬íšŒí†µë…**ì„ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì„œ ë°˜í™˜í•´ì•¼ í•´.
        ë§Œì•½ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ê±°ë‚˜ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, 'ê´€ë ¨ ì‚¬íšŒí†µë… ì •ë³´ ì—†ìŒ'ì´ë¼ê³  ëª…í™•íˆ ì•Œë ¤ì¤˜.
        """)),
        ("human", "{input}\n\n{agent_scratchpad}")
    ])

    agent = create_openai_functions_agent(model, tools, prompt=AGENT_PROMPT)
   
    executor = AgentExecutor(agent=agent, tools=tools, verbose=False) 

    search_query = f"Search for common knowledge about: {state['translated_question']}"
    print(f"Wikipedia ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")

    try:
        result = executor.invoke({"input": search_query})
        
        # ì—ì´ì „íŠ¸ì˜ 'output'ì„ ë°”ë¡œ ì‚¬ìš©í•˜ê¸° ì „ì— ìœ íš¨ì„± ê²€ì‚¬
        if result and result.get("output"):
            social_knowledge_found = result["output"].strip()
            # LLMì´ 'ì •ë³´ ì—†ìŒ'ì´ë¼ê³  ë°˜í™˜í•˜ëŠ” ê²½ìš°ë„ ì²˜ë¦¬
            if social_knowledge_found.lower() in ["ê´€ë ¨ ì‚¬íšŒí†µë… ì •ë³´ ì—†ìŒ", "ì •ë³´ ì—†ìŒ", "no information found", "nothing found", "no relevant information"]:
                state["social_knowledge"] = "ì •ë³´ ì—†ìŒ"
                print(f"Wikipedia ê²€ìƒ‰ ê²°ê³¼: {social_knowledge_found} (LLMì´ ì •ë³´ ì—†ìŒì„ ë°˜í™˜)")
            else:
                state["social_knowledge"] = social_knowledge_found
                print(f"Wikipedia ê²€ìƒ‰ ì„±ê³µ! ì‚¬íšŒí†µë…: {state['social_knowledge']}")
        else:
            state["social_knowledge"] = "ì •ë³´ ì—†ìŒ"
            print("Wikipedia ê²€ìƒ‰ ì‹¤íŒ¨ ë˜ëŠ” LLMì´ ìœ íš¨í•œ outputì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ.")
    except Exception as e:
        state["social_knowledge"] = "ì •ë³´ ì—†ìŒ"
        print(f"Wikipedia Agent ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return state

def get_latest_papers(state: CompareState) -> CompareState:
    """
    ì—¬ëŸ¬ Chroma Vector Storeì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì„ê³„ê°’ì„ ì ìš©í•˜ì—¬ ìµœì‹  ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ëŠ” ë…¸ë“œ.
    """
    print(f"\n--- get_latest_papers ---")
    all_retrieved_docs_contents = []
    found_any_data = False

    for db_config in CHROMA_DBS_CONFIG:
        current_persist_dir = db_config["persist_directory"]
        current_collection_name = db_config["collection_name"]
        
        # print(f"ğŸ” {current_persist_dir}/{current_collection_name} ì—ì„œ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ (k={state['k_value']}, ìœ ì‚¬ë„ ì„ê³„ê°’={COSINE_SIMILARITY_THRESHOLD})...")
        try:
            current_db = Chroma(
                collection_name=current_collection_name,
                persist_directory=current_persist_dir,
                embedding_function=embedding_model
            )
            
            search_results_with_scores = current_db.similarity_search_with_score(
                state["translated_question"],
                k=state["k_value"]
            )
            
            filtered_docs_count = 0
            for doc, score in search_results_with_scores:
                if score < (1 - COSINE_SIMILARITY_THRESHOLD): 
                    all_retrieved_docs_contents.append(doc.page_content)
                    found_any_data = True
                    filtered_docs_count += 1
            #         print(f"   - ë¬¸ì„œ ë°œê²¬ (ì ìˆ˜: {score:.4f}, ë‚´ìš© ì¼ë¶€: {doc.page_content[:50]}...)")
            #     else:
            #         print(f"   - ë¬¸ì„œ í•„í„°ë§ë¨ (ì ìˆ˜: {score:.4f}, ì„ê³„ê°’ {1 - COSINE_SIMILARITY_THRESHOLD:.4f} ì´ˆê³¼)")

            # if filtered_docs_count > 0:
            #     print(f"âœ… {current_persist_dir}/{current_collection_name} ì—ì„œ ì„ê³„ê°’ í†µê³¼ ë¬¸ì„œ {filtered_docs_count}ê°œ ë°œê²¬.")
            # else:
            #     print(f"â— {current_persist_dir}/{current_collection_name} ì—ì„œ ì„ê³„ê°’ í†µê³¼ ë¬¸ì„œ ë°œê²¬ ì•ˆë¨.")

        except Exception as e:
            print(f"âŒ {current_persist_dir}/{current_collection_name} ë¡œë“œ ë˜ëŠ” ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

    state["latest_docs"] = all_retrieved_docs_contents
    state["db_has_data"] = found_any_data # í•˜ë‚˜ë¼ë„ ìœ íš¨í•œ ë¬¸ì„œê°€ ë°œê²¬ë˜ë©´ True

    if not found_any_data:
        print("â— ëª¨ë“  Chroma DBì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ë¬¸ì„œê°€ (ì„ê³„ê°’ ê¸°ì¤€) ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    return state


def compare_and_summarize(state: CompareState) -> CompareState:
    """
    ì‚¬íšŒ í†µë…ê³¼ ìµœì‹  ë…¼ë¬¸ ì •ë³´ë¥¼ ë¹„êµí•˜ì—¬ ìµœì¢… ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ.
    """
    print(f"\n--- compare_and_summarize ---")
    social_knowledge_content = state["social_knowledge"] if state["social_knowledge"] else "ì •ë³´ ì—†ìŒ"
    latest_docs_content = "\n\n".join(state["latest_docs"]) if state["latest_docs"] else "ì •ë³´ ì—†ìŒ"

    db_status_message = ""

    if not state["db_has_data"]:
        db_status_message = "ì°¸ê³ : ìµœì‹  ì˜í•™ ë…¼ë¬¸ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ì£¼ì œì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ê°€ í˜„ì¬ ë¶€ì¡±í•˜ê±°ë‚˜ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    else:
        db_status_message = ""

    prompt_value = COMPARE_PROMPT.format(
        question=state["question"],
        social_knowledge=social_knowledge_content,
        latest_docs=latest_docs_content,
        db_status_message=db_status_message 
    )
    response = model.invoke(prompt_value)
    state["final_answer"] = response.content
    print(f"ìµœì¢… ìš”ì•½ ìƒì„± ì™„ë£Œ.")
    return state


def build_compare_graph():
    """
    LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    """
    workflow = StateGraph(CompareState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("translate_question", translate_question)
    workflow.add_node("agent_search", agent_search)
    workflow.add_node("get_latest_papers", get_latest_papers)
    workflow.add_node("compare_and_summarize", compare_and_summarize)

    # ì‹œì‘ì  ì„¤ì •
    workflow.set_entry_point("translate_question")
    workflow.add_edge("translate_question", "agent_search")
    workflow.add_edge("agent_search", "get_latest_papers")
    workflow.add_edge("get_latest_papers", "compare_and_summarize")
    workflow.add_edge("compare_and_summarize", END)

    return workflow.compile()